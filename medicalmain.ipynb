{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SujayKrish03/Medical-image-classifier/blob/main/medicalmain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "                                        **Medical and Non Medical Image Classifier**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hf6ylviySRC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code imports libraries for building a CNN-based medical image classifier using PyTorch, enabling image preprocessing, dataset loading, and model training for tasks like disease detection from X-rays or MRIs. It also includes tools for web scraping medical images, file management, and image processing to support data collection and preparation."
      ],
      "metadata": {
        "id": "zGh4csyHQ4v-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yohTiipCiO5P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import os\n",
        "from PIL import Image\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysFoarHliQDO"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6u3UtlMWiY-O"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3WeSYtqiius"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "M7y6L_MSilSu"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets list || echo \"Kaggle API setup failed. Check kaggle.json.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJul_ewNjBYH"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/data/chest_xray', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing(Downloading) the medical dataset from kaggle"
      ],
      "metadata": {
        "id": "XoKM5_NqRaMf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCQ_7o4giolQ"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "!unzip -q chest-xray-pneumonia.zip -d /content/data/chest_xray/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9hQEGa3ithi"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "cifar10_dataset = CIFAR10(root='/content/data/cifar10', train=True, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL2DtQ8Hjc17"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/data/train/medical', exist_ok=True)\n",
        "os.makedirs('/content/data/train/non-medical', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRH29wK6jpQC"
      },
      "outputs": [],
      "source": [
        "!mv /content/data/chest_xray/chest_xray/train/NORMAL/* /content/data/train/medical/ 2>/dev/null\n",
        "!mv /content/data/chest_xray/chest_xray/train/PNEUMONIA/* /content/data/train/medical/ 2>/dev/null\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Xen4Xz-jtLw"
      },
      "outputs": [],
      "source": [
        "for i, (image, _) in enumerate(cifar10_dataset):\n",
        "    image.save(f'/content/data/train/non-medical/image_{i}.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmeFU02Wj2mc"
      },
      "outputs": [],
      "source": [
        "!ls /content/data/train/medical | wc -l  # Count medical images\n",
        "!ls /content/data/train/non-medical | wc -l  # Count non-medical images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It resizes images to a uniform 224x224 resolution, converts them to PyTorch tensors, and normalizes pixel values using a mean and standard deviation of 0.485 and 0.229, respectively"
      ],
      "metadata": {
        "id": "KClq9GKgRzzi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV5JC9TBj77o"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.485, 0.485], std=[0.229, 0.229, 0.229])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKj0N3MTj_FI"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    train_dataset = datasets.ImageFolder(root=\"/content/data/train\", transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    print(f\"Dataset loaded with classes: {train_dataset.classes}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a `SimpleCNN` class, a basic Convolutional Neural Network (CNN) for a medical image classifier, built using PyTorch's `nn.Module`. In the `__init__` method, it initializes a convolutional layer (`conv1`) that takes 3-channel input images (e.g., RGB medical images), applies 16 filters of size 3x3 with padding, followed by a max-pooling layer (`pool`) to reduce spatial dimensions by half, and a fully connected layer (`fc1`) that outputs scores for two classes (e.g., medical vs. non-medical or disease vs. no disease). The `forward` method processes input images through convolution, ReLU activation, pooling, flattening, and the final linear layer to produce classification outputs, suitable for binary medical image classification tasks like detecting abnormalities in X-rays or MRIs."
      ],
      "metadata": {
        "id": "-5xl6MAqR48H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE65or6WkBoh"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 112 * 112, 2)  # 2 classes: medical, non-medical\n",
        "    def forward(self, x):\n",
        "     x = self.pool(torch.relu(self.conv1(x)))\n",
        "     x = x.view(x.size(0), -1)  # Flatten dynamically\n",
        "     x = self.fc1(x)\n",
        "     return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1JI6Xk4kEOJ"
      },
      "outputs": [],
      "source": [
        "model = SimpleCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet implements the training loop for the `SimpleCNN` medical image classifier over 5 epochs. In each epoch, it sets the model to training mode, iterates through batches of images and labels from `train_loader`, moves data to the specified device (GPU/CPU), computes the forward pass, calculates the loss using a predefined `criterion` (e.g., cross-entropy loss), backpropagates the gradients, and updates the model parameters with the `optimizer`. The running loss is accumulated and averaged over the number of batches, printing the average loss per epoch to monitor training progress for classifying medical images, such as identifying diseases in X-rays or MRIs."
      ],
      "metadata": {
        "id": "g-VmkNrbR-Ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xWVCSsjkGjq"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3Z8MQzhkJf5"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'medical_non_medical_model.pth')\n",
        "print(\"Model saved as medical_non_medical_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\"/content/data/train\", transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "LzGa5hdC6dwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Test Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "A73_yb636h6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_images_from_url(url, save_dir=\"web_images\"):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching webpage {url}: {e}\")\n",
        "        return []\n",
        "\n",
        "    img_urls = []\n",
        "    img_tags = soup.find_all('img')\n",
        "    for img in img_tags:\n",
        "        src = img.get('src')\n",
        "        if src and (src.endswith('.jpg') or src.endswith('.jpeg') or src.endswith('.png')):\n",
        "            if not src.startswith('http'):\n",
        "                src = urllib.parse.urljoin(url, src)\n",
        "            img_urls.append(src)\n",
        "\n",
        "    downloaded_paths = []\n",
        "    for i, img_url in enumerate(img_urls):\n",
        "        try:\n",
        "            img_name = os.path.join(save_dir, f'image_{i}.jpg')\n",
        "            urllib.request.urlretrieve(img_url, img_name)\n",
        "            downloaded_paths.append((img_name, img_url))  # Store path and URL\n",
        "            print(f\"Downloaded: {img_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {img_url}: {e}\")\n",
        "\n",
        "    return downloaded_paths"
      ],
      "metadata": {
        "id": "VmFhawdx4KwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image_path, model, transform, device):\n",
        "    try:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = transform(image).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(image)\n",
        "            probabilities = torch.softmax(output, dim=1)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            class_names = ['medical', 'non-medical']\n",
        "            predicted_class = class_names[predicted.item()]\n",
        "            confidence = probabilities[0][predicted.item()].item()\n",
        "        return predicted_class, confidence\n",
        "    except Exception as e:\n",
        "        return None, f\"Error processing {image_path}: {e}\""
      ],
      "metadata": {
        "id": "A6bhqPM74Qbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('medical_non_medical_model.pth', map_location=device))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "L_u6pL-k4U4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The download_images_from_url function is designed to scrape and download images from a specified webpage, which can be used to collect medical images (e.g., X-rays, MRIs) for a CNN-based medical classifier. It creates a directory (save_dir, defaulting to \"web_images\")"
      ],
      "metadata": {
        "id": "Mn7DPgsmSHaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://en.wikipedia.org/wiki/Sachin_Tendulkar\"\n",
        "image_paths_urls = download_images_from_url(url)"
      ],
      "metadata": {
        "id": "rPDBQ5g14Y76",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_path, image_url in image_paths_urls:\n",
        "    predicted_class, confidence = predict_image(image_path, model, transform, device)\n",
        "    if predicted_class:\n",
        "        print(f\"Image: {image_path}, URL: {image_url}, Predicted: {predicted_class}, Confidence: {confidence:.4f}\")\n",
        "    else:\n",
        "        print(f\"Image: {image_path}, URL: {image_url}, Error: {confidence}\")"
      ],
      "metadata": {
        "id": "Ugtv3jes4my6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils\n"
      ],
      "metadata": {
        "id": "yOdhnDmyNBz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "def extract_images_from_pdf(pdf_files, save_dir=\"pdf_images\"):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    extracted_paths = []\n",
        "    for pdf_file in pdf_files:\n",
        "        try:\n",
        "            # Convert PDF to images\n",
        "            images = convert_from_path(pdf_file)\n",
        "            pdf_name = os.path.basename(pdf_file)\n",
        "            for i, image in enumerate(images):\n",
        "                img_name = os.path.join(save_dir, f'{pdf_name}_page_{i+1}.jpg')\n",
        "                image.save(img_name, 'JPEG')\n",
        "                extracted_paths.append((img_name, None, pdf_name))  # None for URL\n",
        "                print(f\"Extracted: {img_name} from {pdf_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing PDF {pdf_file}: {e}\")\n",
        "\n",
        "    return extracted_paths\n"
      ],
      "metadata": {
        "id": "PabeJJEgNE39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload PDF files\n",
        "uploaded_pdfs = files.upload()\n",
        "pdf_paths = list(uploaded_pdfs.keys())\n",
        "\n",
        "# Extract and classify\n",
        "extracted_images = extract_images_from_pdf(pdf_paths)\n",
        "\n",
        "for image_path, _, source_pdf in extracted_images:\n",
        "    predicted_class, confidence = predict_image(image_path, model, transform, device)\n",
        "    if predicted_class:\n",
        "        print(f\"Image: {image_path}, Source PDF: {source_pdf}, Predicted: {predicted_class}, Confidence: {confidence:.4f}\")\n",
        "    else:\n",
        "        print(f\"Image: {image_path}, Source PDF: {source_pdf}, Error: {confidence}\")\n"
      ],
      "metadata": {
        "id": "mRraWBj4O2WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio pdf2image\n",
        "!apt-get install -y poppler-utils\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "t-B_4HbKO491"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing a simple UI for the task using Gradio"
      ],
      "metadata": {
        "id": "mxwvmcu0SKwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "\n",
        "# Assume these are already defined and imported:\n",
        "# - predict_image(image_path, model, transform, device)\n",
        "# - download_images_from_url(url) → returns List[(img_path, img_url)]\n",
        "# - extract_images_from_pdf(pdf_paths) → returns List[(img_path, page_num, pdfname)]\n",
        "\n",
        "# 🔹 Predict for Single Image Upload\n",
        "def predict_single_image(image):\n",
        "    if image is None:\n",
        "        return []\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".jpg\") as temp_file:\n",
        "        temp_path = temp_file.name\n",
        "        image.save(temp_path)\n",
        "\n",
        "    pred, conf = predict_image(temp_path, model, transform, device)\n",
        "    return [(temp_path, f\"{pred} ({conf:.2f})\")]\n",
        "\n",
        "# 🔹 Predict from URL (Scrape and classify multiple images)\n",
        "def predict_from_url(url):\n",
        "    results = []\n",
        "    image_paths = download_images_from_url(url)\n",
        "\n",
        "    for img_path, img_url in image_paths:  # limit for performance\n",
        "        pred, conf = predict_image(img_path, model, transform, device)\n",
        "        results.append((img_path, f\"{pred} ({conf:.2f})\"))\n",
        "    return results\n",
        "\n",
        "# 🔹 Predict from PDF (Extract images and classify)\n",
        "def predict_from_pdf(pdf):\n",
        "    if pdf is None:\n",
        "        return []\n",
        "\n",
        "    with open(\"temp.pdf\", \"wb\") as f:\n",
        "        f.write(pdf.read())\n",
        "\n",
        "    extracted = extract_images_from_pdf([\"temp.pdf\"])\n",
        "    results = []\n",
        "    for img_path, _, _ in extracted:  # Limit for speed\n",
        "        pred, conf = predict_image(img_path, model, transform, device)\n",
        "        results.append((img_path, f\"{pred} ({conf:.2f})\"))\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "x4llmbWYO7IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### 🩻 Medical vs Non-Medical Image Classifier\")\n",
        "\n",
        "    with gr.Tab(\"Single Image Upload\"):\n",
        "        img_input = gr.Image(type=\"pil\")\n",
        "        img_btn = gr.Button(\"Classify Image\")\n",
        "        img_out = gr.Gallery(label=\"Prediction\", show_label=True, columns=3, height=300)\n",
        "\n",
        "\n",
        "    with gr.Tab(\"From URL\"):\n",
        "        url_input = gr.Textbox(label=\"Enter Web Page URL\")\n",
        "        url_btn = gr.Button(\"Fetch & Classify\")\n",
        "        url_out = gr.Gallery(label=\"Predictions\", show_label=True, columns=3, height=300)\n",
        "\n",
        "\n",
        "    with gr.Tab(\"From PDF\"):\n",
        "        pdf_input = gr.File(file_types=[\".pdf\"], label=\"Upload PDF\")\n",
        "        pdf_btn = gr.Button(\"Extract & Classify\")\n",
        "        pdf_out = gr.Gallery(label=\"Predictions\", show_label=True)\n",
        "\n",
        "    img_btn.click(fn=predict_single_image, inputs=img_input, outputs=img_out)\n",
        "    url_btn.click(fn=predict_from_url, inputs=url_input, outputs=url_out)\n",
        "    pdf_btn.click(fn=predict_from_pdf, inputs=pdf_input, outputs=pdf_out)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "pbH1eJ3-O87L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L-3mETF8nUwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gWJxLUKIoCWB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPsDAsUiteIW1U1VHCm1hLM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}