{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SujayKrish03/Medical-image-classifier/blob/main/medicalmain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "                                        **Medical and Non Medical Image Classifier**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hf6ylviySRC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code imports libraries for building a CNN-based medical image classifier using PyTorch, enabling image preprocessing, dataset loading, and model training for tasks like disease detection from X-rays or MRIs. It also includes tools for web scraping medical images, file management, and image processing to support data collection and preparation."
      ],
      "metadata": {
        "id": "zGh4csyHQ4v-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yohTiipCiO5P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import os\n",
        "from PIL import Image\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ysFoarHliQDO"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "6u3UtlMWiY-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ffed6eb-1226-4748-a3cb-6351ea1cb02f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.7.14)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pkXzRWSkibIM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "d0247185-1ea6-4938-da81-3bbcdd70aa57"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2a97b5d8-4df4-4d48-8429-549b515499ce\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2a97b5d8-4df4-4d48-8429-549b515499ce\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Upload kaggle.json\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload kaggle.json\n",
        "if not os.path.exists('/content/kaggle.json'):\n",
        "    print(\"Error: kaggle.json not uploaded correctly.\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S3WeSYtqiius"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "M7y6L_MSilSu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837e2ff9-754a-4788-d678-a902d9460103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                        title                                                    size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "---------------------------------------------------------  -------------------------------------------------  ----------  --------------------------  -------------  ---------  ---------------  \n",
            "rohitgrewal/airlines-flights-data                          Airlines Flights Data                                 2440299  2025-07-29 09:16:00.463000           8978        161  1.0              \n",
            "wasiqaliyasir/breast-cancer-dataset                        Breast cancer dataset                                   49830  2025-07-30 12:52:44.057000           5326        179  1.0              \n",
            "kunshbhatia/delhi-air-quality-dataset                      Delhi Air Quality Dataset                               30430  2025-07-28 14:00:14.247000           3758         82  1.0              \n",
            "abdulmalik1518/cars-datasets-2025                          Cars Datasets (2025)                                    25987  2025-07-17 21:43:28.493000          10784        237  1.0              \n",
            "rohitgrewal/restaurant-sales-data                          Restaurant Sales Data                                    2237  2025-07-31 17:29:16.597000           1715         27  1.0              \n",
            "rohitgrewal/netflix-data                                   Netflix Data                                          1224095  2025-07-31 06:07:40.333000           1749         33  1.0              \n",
            "sahilislam007/college-student-placement-factors-dataset    College Student Placement Factors Dataset              110450  2025-07-02 08:33:50.547000          11641        217  1.0              \n",
            "younusmohamed/payment-fraud-empowering-financial-security  Payment Fraud - Empowering Financial Security          319948  2025-08-02 08:40:49.427000            503         23  1.0              \n",
            "anandshaw2001/top-spotify-songs-in-countries               Top Spotify Listening History Songs in Countries      6389288  2025-06-15 05:01:56                  6561        153  1.0              \n",
            "shamimhasan8/education-inequality-data                     Education Inequality Data                               28283  2025-07-29 03:19:04.740000           1142         25  1.0              \n",
            "ankushpanday2/indian-kids-screentime-2025                  Indian Kids Screentime 2025                             70001  2025-07-08 17:25:35.483000           6325        103  1.0              \n",
            "reignrichard/coffee-store-sales                            Coffee Store Sales                                     426152  2025-07-11 12:23:43.847000           3427         45  0.9411765        \n",
            "divyaraj2006/credit-card-spending-in-india                 Credit Card Spending in India                            2047  2025-07-30 02:39:50.310000           1236         28  1.0              \n",
            "atharvasoundankar/sneakers-and-streetwear-sales-2022       ðŸ‘Ÿ Sneakers & Streetwear Sales (2022)                     6320  2025-07-29 08:28:56.377000           1246         28  1.0              \n",
            "rohitgrewal/spotify-youtube-data                           Spotify-YouTube Data                                  9386470  2025-07-26 08:56:33.277000           1120         27  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                      Melbourne Housing Snapshot                             461423  2018-06-05 12:52:24.087000         187804       1655  0.7058824        \n",
            "rohitgrewal/weather-data                                   Weather Data                                           102960  2025-07-30 15:25:37.393000            688         20  1.0              \n",
            "datasnaek/youtube-new                                      Trending YouTube Video Statistics                   210575746  2019-06-03 00:56:47.177000         279757       5743  0.7941176        \n",
            "shamimhasan8/crime-and-safety-dataset                      Crime & Safety Dataset                                  19871  2025-07-29 03:13:38.457000           1542         27  1.0              \n",
            "residentmario/things-on-reddit                             Things on Reddit                                     16773230  2017-10-26 14:10:15.157000          13838        300  0.5882353        \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets list || echo \"Kaggle API setup failed. Check kaggle.json.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uJul_ewNjBYH"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/data/chest_xray', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing(Downloading) the medical dataset from kaggle"
      ],
      "metadata": {
        "id": "XoKM5_NqRaMf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YCQ_7o4giolQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a5a345-794e-42ab-d194-327f522ff4ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
            "License(s): other\n",
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 2.29G/2.29G [00:16<00:00, 174MB/s]\n",
            "100% 2.29G/2.29G [00:16<00:00, 149MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "!unzip -q chest-xray-pneumonia.zip -d /content/data/chest_xray/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s9hQEGa3ithi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5956aa6-e7ab-4ae0-9a55-0fcebff8ed64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:05<00:00, 31.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "cifar10_dataset = CIFAR10(root='/content/data/cifar10', train=True, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cL2DtQ8Hjc17"
      },
      "outputs": [],
      "source": [
        "os.makedirs('/content/data/train/medical', exist_ok=True)\n",
        "os.makedirs('/content/data/train/non-medical', exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sRH29wK6jpQC"
      },
      "outputs": [],
      "source": [
        "!mv /content/data/chest_xray/chest_xray/train/NORMAL/* /content/data/train/medical/ 2>/dev/null\n",
        "!mv /content/data/chest_xray/chest_xray/train/PNEUMONIA/* /content/data/train/medical/ 2>/dev/null\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1Xen4Xz-jtLw"
      },
      "outputs": [],
      "source": [
        "for i, (image, _) in enumerate(cifar10_dataset):\n",
        "    image.save(f'/content/data/train/non-medical/image_{i}.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VmeFU02Wj2mc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2453b03-b34e-4f47-e871-2b52eff10e75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5216\n",
            "50002\n"
          ]
        }
      ],
      "source": [
        "!ls /content/data/train/medical | wc -l  # Count medical images\n",
        "!ls /content/data/train/non-medical | wc -l  # Count non-medical images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It resizes images to a uniform 224x224 resolution, converts them to PyTorch tensors, and normalizes pixel values using a mean and standard deviation of 0.485 and 0.229, respectively"
      ],
      "metadata": {
        "id": "KClq9GKgRzzi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yV5JC9TBj77o"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.485, 0.485], std=[0.229, 0.229, 0.229])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "HKj0N3MTj_FI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b47475-59eb-496e-ccb6-3364088be254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset loaded with classes: ['medical', 'non-medical']\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    train_dataset = datasets.ImageFolder(root=\"/content/data/train\", transform=transform)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    print(f\"Dataset loaded with classes: {train_dataset.classes}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a `SimpleCNN` class, a basic Convolutional Neural Network (CNN) for a medical image classifier, built using PyTorch's `nn.Module`. In the `__init__` method, it initializes a convolutional layer (`conv1`) that takes 3-channel input images (e.g., RGB medical images), applies 16 filters of size 3x3 with padding, followed by a max-pooling layer (`pool`) to reduce spatial dimensions by half, and a fully connected layer (`fc1`) that outputs scores for two classes (e.g., medical vs. non-medical or disease vs. no disease). The `forward` method processes input images through convolution, ReLU activation, pooling, flattening, and the final linear layer to produce classification outputs, suitable for binary medical image classification tasks like detecting abnormalities in X-rays or MRIs."
      ],
      "metadata": {
        "id": "-5xl6MAqR48H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aE65or6WkBoh"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(16 * 112 * 112, 2)  # 2 classes: medical, non-medical\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = x.view(-1, 16 * 112 * 112)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "k1JI6Xk4kEOJ"
      },
      "outputs": [],
      "source": [
        "model = SimpleCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet implements the training loop for the `SimpleCNN` medical image classifier over 5 epochs. In each epoch, it sets the model to training mode, iterates through batches of images and labels from `train_loader`, moves data to the specified device (GPU/CPU), computes the forward pass, calculates the loss using a predefined `criterion` (e.g., cross-entropy loss), backpropagates the gradients, and updates the model parameters with the `optimizer`. The running loss is accumulated and averaged over the number of batches, printing the average loss per epoch to monitor training progress for classifying medical images, such as identifying diseases in X-rays or MRIs."
      ],
      "metadata": {
        "id": "g-VmkNrbR-Ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xWVCSsjkGjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd776a30-a9af-4d99-86d9-fe0cbd9a36bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.0960\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3Z8MQzhkJf5"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'medical_non_medical_model.pth')\n",
        "print(\"Model saved as medical_non_medical_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_images_from_url(url, save_dir=\"web_images\"):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    try:\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"Error fetching webpage {url}: {e}\")\n",
        "        return []\n",
        "\n",
        "    img_urls = []\n",
        "    img_tags = soup.find_all('img')\n",
        "    for img in img_tags:\n",
        "        src = img.get('src')\n",
        "        if src and (src.endswith('.jpg') or src.endswith('.jpeg') or src.endswith('.png')):\n",
        "            if not src.startswith('http'):\n",
        "                src = urllib.parse.urljoin(url, src)\n",
        "            img_urls.append(src)\n",
        "\n",
        "    downloaded_paths = []\n",
        "    for i, img_url in enumerate(img_urls):\n",
        "        try:\n",
        "            img_name = os.path.join(save_dir, f'image_{i}.jpg')\n",
        "            urllib.request.urlretrieve(img_url, img_name)\n",
        "            downloaded_paths.append((img_name, img_url))  # Store path and URL\n",
        "            print(f\"Downloaded: {img_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {img_url}: {e}\")\n",
        "\n",
        "    return downloaded_paths"
      ],
      "metadata": {
        "id": "VmFhawdx4KwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(image_path, model, transform, device):\n",
        "    try:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image = transform(image).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = model(image)\n",
        "            probabilities = torch.softmax(output, dim=1)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "            class_names = ['medical', 'non-medical']\n",
        "            predicted_class = class_names[predicted.item()]\n",
        "            confidence = probabilities[0][predicted.item()].item()\n",
        "        return predicted_class, confidence\n",
        "    except Exception as e:\n",
        "        return None, f\"Error processing {image_path}: {e}\""
      ],
      "metadata": {
        "id": "A6bhqPM74Qbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('medical_non_medical_model.pth', map_location=device))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "L_u6pL-k4U4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The download_images_from_url function is designed to scrape and download images from a specified webpage, which can be used to collect medical images (e.g., X-rays, MRIs) for a CNN-based medical classifier. It creates a directory (save_dir, defaulting to \"web_images\")"
      ],
      "metadata": {
        "id": "Mn7DPgsmSHaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://en.wikipedia.org/wiki/Sachin_Tendulkar\"\n",
        "image_paths_urls = download_images_from_url(url)"
      ],
      "metadata": {
        "id": "rPDBQ5g14Y76",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_path, image_url in image_paths_urls:\n",
        "    predicted_class, confidence = predict_image(image_path, model, transform, device)\n",
        "    if predicted_class:\n",
        "        print(f\"Image: {image_path}, URL: {image_url}, Predicted: {predicted_class}, Confidence: {confidence:.4f}\")\n",
        "    else:\n",
        "        print(f\"Image: {image_path}, URL: {image_url}, Error: {confidence}\")"
      ],
      "metadata": {
        "id": "Ugtv3jes4my6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image\n",
        "!apt-get install -y poppler-utils\n"
      ],
      "metadata": {
        "id": "yOdhnDmyNBz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "def extract_images_from_pdf(pdf_files, save_dir=\"pdf_images\"):\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    extracted_paths = []\n",
        "    for pdf_file in pdf_files:\n",
        "        try:\n",
        "            # Convert PDF to images\n",
        "            images = convert_from_path(pdf_file)\n",
        "            pdf_name = os.path.basename(pdf_file)\n",
        "            for i, image in enumerate(images):\n",
        "                img_name = os.path.join(save_dir, f'{pdf_name}_page_{i+1}.jpg')\n",
        "                image.save(img_name, 'JPEG')\n",
        "                extracted_paths.append((img_name, None, pdf_name))  # None for URL\n",
        "                print(f\"Extracted: {img_name} from {pdf_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing PDF {pdf_file}: {e}\")\n",
        "\n",
        "    return extracted_paths\n"
      ],
      "metadata": {
        "id": "PabeJJEgNE39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload PDF files\n",
        "uploaded_pdfs = files.upload()\n",
        "pdf_paths = list(uploaded_pdfs.keys())\n",
        "\n",
        "# Extract and classify\n",
        "extracted_images = extract_images_from_pdf(pdf_paths)\n",
        "\n",
        "for image_path, _, source_pdf in extracted_images:\n",
        "    predicted_class, confidence = predict_image(image_path, model, transform, device)\n",
        "    if predicted_class:\n",
        "        print(f\"Image: {image_path}, Source PDF: {source_pdf}, Predicted: {predicted_class}, Confidence: {confidence:.4f}\")\n",
        "    else:\n",
        "        print(f\"Image: {image_path}, Source PDF: {source_pdf}, Error: {confidence}\")\n"
      ],
      "metadata": {
        "id": "mRraWBj4O2WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio pdf2image\n",
        "!apt-get install -y poppler-utils\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "t-B_4HbKO491"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing a simple UI for the task using Gradio"
      ],
      "metadata": {
        "id": "mxwvmcu0SKwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from pdf2image import convert_from_path\n",
        "import os\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "\n",
        "# Assume these are already defined and imported:\n",
        "# - predict_image(image_path, model, transform, device)\n",
        "# - download_images_from_url(url) â†’ returns List[(img_path, img_url)]\n",
        "# - extract_images_from_pdf(pdf_paths) â†’ returns List[(img_path, page_num, pdfname)]\n",
        "\n",
        "# ðŸ”¹ Predict for Single Image Upload\n",
        "def predict_single_image(image):\n",
        "    if image is None:\n",
        "        return []\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".jpg\") as temp_file:\n",
        "        temp_path = temp_file.name\n",
        "        image.save(temp_path)\n",
        "\n",
        "    pred, conf = predict_image(temp_path, model, transform, device)\n",
        "    return [(temp_path, f\"{pred} ({conf:.2f})\")]\n",
        "\n",
        "# ðŸ”¹ Predict from URL (Scrape and classify multiple images)\n",
        "def predict_from_url(url):\n",
        "    results = []\n",
        "    image_paths = download_images_from_url(url)\n",
        "\n",
        "    for img_path, img_url in image_paths:  # limit for performance\n",
        "        pred, conf = predict_image(img_path, model, transform, device)\n",
        "        results.append((img_path, f\"{pred} ({conf:.2f})\"))\n",
        "    return results\n",
        "\n",
        "# ðŸ”¹ Predict from PDF (Extract images and classify)\n",
        "def predict_from_pdf(pdf):\n",
        "    if pdf is None:\n",
        "        return []\n",
        "\n",
        "    with open(\"temp.pdf\", \"wb\") as f:\n",
        "        f.write(pdf.read())\n",
        "\n",
        "    extracted = extract_images_from_pdf([\"temp.pdf\"])\n",
        "    results = []\n",
        "    for img_path, _, _ in extracted:  # Limit for speed\n",
        "        pred, conf = predict_image(img_path, model, transform, device)\n",
        "        results.append((img_path, f\"{pred} ({conf:.2f})\"))\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "x4llmbWYO7IP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"### ðŸ©» Medical vs Non-Medical Image Classifier\")\n",
        "\n",
        "    with gr.Tab(\"Single Image Upload\"):\n",
        "        img_input = gr.Image(type=\"pil\")\n",
        "        img_btn = gr.Button(\"Classify Image\")\n",
        "        img_out = gr.Gallery(label=\"Prediction\", show_label=True, columns=3, height=300)\n",
        "\n",
        "\n",
        "    with gr.Tab(\"From URL\"):\n",
        "        url_input = gr.Textbox(label=\"Enter Web Page URL\")\n",
        "        url_btn = gr.Button(\"Fetch & Classify\")\n",
        "        url_out = gr.Gallery(label=\"Predictions\", show_label=True, columns=3, height=300)\n",
        "\n",
        "\n",
        "    with gr.Tab(\"From PDF\"):\n",
        "        pdf_input = gr.File(file_types=[\".pdf\"], label=\"Upload PDF\")\n",
        "        pdf_btn = gr.Button(\"Extract & Classify\")\n",
        "        pdf_out = gr.Gallery(label=\"Predictions\", show_label=True)\n",
        "\n",
        "    img_btn.click(fn=predict_single_image, inputs=img_input, outputs=img_out)\n",
        "    url_btn.click(fn=predict_from_url, inputs=url_input, outputs=url_out)\n",
        "    pdf_btn.click(fn=predict_from_pdf, inputs=pdf_input, outputs=pdf_out)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "pbH1eJ3-O87L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L-3mETF8nUwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gWJxLUKIoCWB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMDXVrNU1C11uBhQ+U9lpJP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}